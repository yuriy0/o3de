/*
* All or portions of this file Copyright (c) Amazon.com, Inc. or its affiliates or
* its licensors.
*
* For complete copyright and license terms please see the LICENSE at the root of this
* distribution (the "License"). All use of this software is governed by the License,
* or, if provided, by the license below or the license accompanying this file. Do not
* remove or modify any license notices. This file is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
*
* ==============================================================================
*
* Modifications copyright 2021 Apocalypse Studios Inc., all rights reserved
*/

#include <viewsrg.srgi>
#include <Apc/Features/Pbr/TransparentRefractivePassSrg.azsli>
#include "Hair_Common.azsli"
#include <Atom/Features/PBR/DefaultObjectSrg.azsli>
#include <Atom/Features/ScreenSpace/ScreenSpaceUtil.azsli>
#include <Apc/Features/Pbr/MathUtil.azsli>
#include <Apc/Features/OIT/MomentMath.azsli>

struct ForwardPassOutput
{
    float4 m_alpha  : SV_Target0;
    float4 m_beta : SV_Target1;
    float4 m_test : SV_Target2;
};

struct ForwardPassOutputWithDepth
{
    float4 m_alpha  : SV_Target0;
    float4 m_beta : SV_Target1;
    float4 m_test : SV_Target2;
    float m_depth : SV_Depth;
};



#include <Atom/Features/ColorManagement/TransformColor.azsli>

// ---------- Material Parameters ----------

COMMON_OPTIONS_BASE_COLOR()
COMMON_OPTIONS_ROUGHNESS()
COMMON_OPTIONS_METALLIC()
COMMON_OPTIONS_SPECULAR_F0()
COMMON_OPTIONS_NORMAL()
COMMON_OPTIONS_CLEAR_COAT()
COMMON_OPTIONS_OCCLUSION()
COMMON_OPTIONS_EMISSIVE()

// Alpha
//#include "MaterialInputs_Apc/AlphaInput.azsli"

// Subsurface
#include "MaterialInputs/SubsurfaceInput.azsli"

// Transmission
#include "MaterialInputs/TransmissionInput.azsli"

// OIT
option enum class OrderIndependentWeightFunction
{
    Standard,
    NearDepthRelativeExponential
} o_oit_weight_function;

struct VSInput
{
    // Base fields (required by the template azsli file)...
    float3 m_position : POSITION;
    float3 m_normal : NORMAL;
    float4 m_tangent : TANGENT; 
    float3 m_bitangent : BITANGENT; 
 
    // Extended fields (only referenced in this azsl file)...
    float2 m_uv0 : UV0;
    float2 m_uv1 : UV1;
};

struct VSOutput
{
    // Base fields (required by the template azsli file)...
    // "centroid" is needed for SV_DepthLessEqual to compile
    linear centroid float4 m_position : SV_Position;
    float3 m_normal: NORMAL;
    float3 m_tangent : TANGENT; 
    float3 m_bitangent : BITANGENT; 
    float3 m_worldPosition : UV0;
    float3 m_shadowCoords[ViewSrg::MaxCascadeCount] : UV6;

    // Extended fields (only referenced in this azsl file)...
    float2 m_uv[UvSetCount] : UV1; // UV1,UV2 because UvSetCount=2
	float3 m_ssUV : UV5;
};

#include <Atom/Features/PBR/AlphaUtils.azsli>
#include <Atom/Features/Vertex/VertexHelper.azsli>
#include <Atom/Features/PBR/Lighting/HairLighting.azsli>

// Convert from clip space XYW to screen space UV
float2 GetScreenSpaceUV(float3 clip)
{
	float2 uv = (clip.xy / clip.z) * 0.5 + 0.5;
	uv.y = 1.0 - uv.y;
	return uv;
}

VSOutput StandardPbr_ForwardPassVS(VSInput IN)
{
    VSOutput OUT;
 
    float3 worldPosition = mul(ObjectSrg::GetWorldMatrix(), float4(IN.m_position, 1.0)).xyz;

    // By design, only UV0 is allowed to apply transforms.
    OUT.m_uv[0] = mul(MaterialSrg::m_uvMatrix, float3(IN.m_uv0, 1.0)).xy;
    OUT.m_uv[1] = IN.m_uv1;

    bool skipShadowCoords = false;
    VertexHelper(IN, OUT, worldPosition, skipShadowCoords);
    
	OUT.m_ssUV = OUT.m_position.xyw;
	
    return OUT;
}

#define TRANSPARENT_PASS

#include "Hair_PS_Common.azsli"

#undef TRANSPARENT_PASS

struct IOTBlendInput
{
	float4 m_diffuseColor;
	float4 m_specularColor;
	float3 m_transmittanceTint;
	float3 m_surfaceNormal;
	float3 m_wsPos;
	float3 m_ssPos;
    float3 m_worldPosition;
};

struct IOTBlendOutput
{
	float4 m_alpha;
	float3 m_beta;
	float m_diffusion;
	float2 m_pixelOffset;
	
	float4 m_test;
};

// Equation 9
float2 GetRefractionPixelOffset(float3 surfaceNormal, float3 wsPos, float ior)
{
	// TODO
	return float2(0,0);
}

/*
    Based on "A Phenomenological Scattering Model for Order-Independent Transparency", McGuire & Mara
    https://research.nvidia.com/publication/phenomenological-scattering-model-order-independent-transparency
*/
IOTBlendOutput IOTBlend(IOTBlendInput IN)
{
	IOTBlendOutput OUT;
	float2 ssUV = GetScreenSpaceUV(IN.m_ssPos);
	float alpha = IN.m_diffuseColor.a;

    // Special handling when the source alpha is one: treat the surface as opaque
    bool sourceAlphaIsOne = alpha == 1.0;

    // Equation 4: `alpha_i * (1 - hat(t_i))' is named net coverage
    float netCoverage = sourceAlphaIsOne ? 1.0 : alpha * (1.0 - dot(IN.m_transmittanceTint, f3_unit(1.0/3.0)));

    // Equation 5: distance based weighting factor
    // Not physical, only requirements are: monotonic and superlinear wrt depth
    // Note that the term inside the exponent is arbitrarily scaled to avoid precision issues
    // The alpha term is eventually divided out of the RGB color term, so any fixed multiple
    // of the weight gives the same analytic result    
    float weight = 1.0;
    {
        float2 momentDim;
        PassSrg::m_oitMoments.GetDimensions(momentDim.x, momentDim.y);

        int3 coord = int3(int2(momentDim * ssUV), 0);

        float totalOpticalDepth = PassSrg::m_oitOpticalDepth.Load(coord);
        clip(totalOpticalDepth - 0.00100050033f); // avoids divide by zero

        float4 moments = PassSrg::m_oitMoments.Load(coord);
        float depth = 1.0 - IN.m_wsPos.z;

        /* `bias' and `bias_vector' come from Table 1 of "Supplementary Document on
           Moment-Based Order-Independent Transparency", Munstermann et al.
           `overestimation' is suggested in the same
         */
        const float4 bias_vector = float4(0, 0.375, 0, 0.375);
        const float bias = 5e-7;
        const float overestimation = 0.25;

        weight = GetTransmittanceAtDepth_4P(
            totalOpticalDepth, moments, depth,
            bias,
            overestimation,
            bias_vector
        );
    }

    // Equation 4
	OUT.m_alpha = float4((IN.m_diffuseColor.rgb + IN.m_specularColor.rgb), netCoverage) * weight; 
        
    // Equation 2: "Beta", i.e. coverage per colour channel
    // NOTE: the equation as given is:
    //   prod{i}(1 - a_i + a_i * t_i)
    // but the blend op computes
    //   prod{i}(1 - beta), where beta = a_i * (1 - t_i)
    // NOTE: the code in the paper scales beta down by 1/3. this clamps beta to 1/3 when transmissionTint = 1 and alpha = 1
    // but, this seems wrong because getting to low accumulated transmittance (i.e. beta ~ 1) becomes impossible
    OUT.m_beta = sourceAlphaIsOne ? f3_unit(1.0) : alpha * (f3_unit(1.0) - IN.m_transmittanceTint);
	
    // Diffusion/refraction disabled for hair
    OUT.m_diffusion = 0.0;
    OUT.m_pixelOffset = f2_unit(0.0);

    // float minTranspZ = LinerizeDepth(PassSrg::m_depthMin.Sample(PassSrg::LinearSampler, ssUV).x);
    // OUT.m_test = float4(0,0,0,0);
    // OUT.m_test.x = fragZ - minTranspZ;
    // OUT.m_test.y = OUT.m_test.x / ViewSrg::GetFarZ();
    // OUT.m_test.z = OUT.m_test.x / ViewSrg::GetNearZ();
    // OUT.m_test.w = exp(-max(OUT.m_test.x, 0.0));

	return OUT;
}

IOTBlendInput MakeIOTBlendInput(VSOutput IN, PbrLightingOutput lightingOutput, float3 wsNormal)
{
	IOTBlendInput iotBlendInput;
	iotBlendInput.m_diffuseColor        = lightingOutput.m_diffuseColor;
	iotBlendInput.m_specularColor       = lightingOutput.m_specularColor;
	iotBlendInput.m_transmittanceTint   = MaterialSrg::m_transmittanceTintForTransparent;
	iotBlendInput.m_surfaceNormal       = wsNormal;
	iotBlendInput.m_wsPos               = IN.m_position.xyz;
	iotBlendInput.m_ssPos               = IN.m_ssUV;
    iotBlendInput.m_worldPosition       = IN.m_worldPosition;
    return iotBlendInput;
}

ForwardPassOutputWithDepth StandardPbr_ForwardPassPS(VSOutput IN, bool isFrontFace : SV_IsFrontFace)
{
    ForwardPassOutputWithDepth OUT;
    float depth;
    float3 wsNormal;

    PbrLightingOutput lightingOutput = ForwardPassPS_Common(IN, isFrontFace, depth, wsNormal);
	
	IOTBlendOutput iotBlendOutput = IOTBlend(MakeIOTBlendInput(IN, lightingOutput, wsNormal));
    
    OUT.m_alpha = iotBlendOutput.m_alpha;
    OUT.m_beta.rgb = iotBlendOutput.m_beta;
    OUT.m_beta.a = iotBlendOutput.m_diffusion;
	OUT.m_test = iotBlendOutput.m_test;
	
    OUT.m_depth = depth;
    return OUT;
}

[earlydepthstencil]
ForwardPassOutput StandardPbr_ForwardPassPS_EDS(VSOutput IN, bool isFrontFace : SV_IsFrontFace)
{
    ForwardPassOutput OUT;
    float depth;
    float3 wsNormal;

    PbrLightingOutput lightingOutput = ForwardPassPS_Common(IN, isFrontFace, depth, wsNormal);
	
	IOTBlendOutput iotBlendOutput = IOTBlend(MakeIOTBlendInput(IN, lightingOutput, wsNormal));
    
    OUT.m_alpha = iotBlendOutput.m_alpha;
    OUT.m_beta.rgb = iotBlendOutput.m_beta;
    OUT.m_beta.a = iotBlendOutput.m_diffusion;
	OUT.m_test = iotBlendOutput.m_test;

    return OUT;
}
